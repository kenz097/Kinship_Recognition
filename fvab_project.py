# -*- coding: utf-8 -*-
"""FVAB Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hU73Bwo3Bew9i5u3tOvctrCXJxv8INPT

##**Importiamo l'account di google drive contenente i dataset e i file csv**
"""

from google.colab import drive
drive.mount('/content/drive')

"""##**Estraiamo i file zip contenenti i dataset e li spostiamo in locale**



"""

!unzip /content/drive/Shareddrives/Progetto_FVAB_File/test.zip -d /content/test/
!unzip /content/drive/Shareddrives/Progetto_FVAB_File/train.zip -d /content/train/
!unzip /content/drive/Shareddrives/Progetto_FVAB_File/KinFaceW-I.zip

"""##**Importiamo le librerie**"""

#some of blocks below are not used.

# Data manipulation
import numpy as np
import pandas as pd

# Data visualisation
import matplotlib.pyplot as plt

# Fastai
from fastai.vision import *
from fastai.vision.models import *

# PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.utils
import torchvision.datasets as dset

from torch import optim
from torch.utils.data import DataLoader,Dataset
from torchvision.models import *
from torchvision.datasets import ImageFolder
from torch.autograd import Variable
#import pretrainedmodels

from pathlib import Path
import sys

from glob import glob
from PIL import Image

import scipy.io
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

"""##**impostiamo i valori al bach size, al numero di epoche e alla grandezza delle immagini**"""

np.random.seed(42)#To make sure that each time you run this kernal, you will get the same beginning parameters.

BATCH_SIZE=16
NUMBER_EPOCHS=20
IMG_SIZE=100

"""##**Funzioni per creare una tabella 2x8 per stampare i risultati di un test**"""

def imshow(img,text=None,should_save=False):#for showing the data you loaded to dataloader
    npimg = img.numpy()
    plt.axis("off")
    if text:
        plt.text(75, 8, text, style='italic',fontweight='bold',
            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()    

def show_plot(iteration,loss):# for showing loss value changed with iter
    plt.plot(iteration,loss)
    plt.show()

"""##**importiamo le immagini dalla cartella "train" e recuperiamo il loro accoppiamento tramite il file "train_relationship.csv"**"""

#F09xx are used for validation.
val_famillies = "F09"

#An example of data:"../input/train/F00002/MID1/P0001_face1.jpg"
all_images = glob("train/*/*/*.jpg")

train_images = [x for x in all_images if val_famillies not in x]
val_images = [x for x in all_images if val_famillies in x]

train_person_to_images_map = defaultdict(list)#Put the link of each picture under the key word of a person such as "F0002/MID1"
for x in train_images:
    train_person_to_images_map[x.split("/")[-3] + "/" + x.split("/")[-2]].append(x)

val_person_to_images_map = defaultdict(list)
for x in val_images:
    val_person_to_images_map[x.split("/")[-3] + "/" + x.split("/")[-2]].append(x)

ppl = [x.split("/")[-3] + "/" + x.split("/")[-2] for x in all_images]
relationships = pd.read_csv("/content/drive/Shareddrives/Progetto_FVAB_File/train_relationships.csv")
relationships = list(zip(relationships.p1.values, relationships.p2.values))#For a List like[p1 p2], zip can return a result like [(p1[0],p2[0]),(p1[1],p2[1]),...]
relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]#filter unused relationships
train = [x for x in relationships if val_famillies not in x[0]]
val = [x for x in relationships if val_famillies in x[0]]

print("Total train pairs:", len(train))    
print("Total val pairs:", len(val))

"""##**definiamo la classe che utilizziamo durante la fase di training per ricevere le coppia su cui la rete deve allenarsi, con solo due classi 0 ed 1**"""

class trainingDataset(Dataset):#Get two images and whether they are related.
    
    def __init__(self,imageFolderDataset, relationships, transform=None):
        self.imageFolderDataset = imageFolderDataset    
        self.relationships = relationships #choose either train or val dataset to use
        self.transform = transform
        
    def __getitem__(self,index):
        img0_info = self.relationships[index][0]#for each relationship in train_relationships.csv, the first img comes from first row, and the second is either specially choosed related person or randomly choosed non-related person
        img0_path = glob("train/"+img0_info+"/*.jpg")
        img0_path = random.choice(img0_path)
        
        cand_relationships = [x for x in self.relationships if x[0]==img0_info or x[1]==img0_info]#found all candidates related to person in img0
        if cand_relationships==[]:#in case no relationship is mensioned. But it is useless here because I choose the first person line by line.
            should_get_same_class = 0
        else:
            should_get_same_class = random.randint(0,1) 

        if should_get_same_class==1:#1 means related, and 0 means non-related.
            img1_info = random.choice(cand_relationships)#choose the second person from related relationships
            if img1_info[0]!=img0_info:
                img1_info=img1_info[0]
            else:
                img1_info=img1_info[1]
            img1_path = glob("train/"+img1_info+"/*.jpg")#randomly choose a img of this person
            img1_path = random.choice(img1_path)
        else:#0 means non-related
            randChoose = True#in case the chosen person is related to first person
            while randChoose:
                img1_path = random.choice(self.imageFolderDataset.imgs)[0]
                img1_info = img1_path.split("/")[-3] + "/" + img1_path.split("/")[-2]
                randChoose = False
                for x in cand_relationships:#if so, randomly choose another person
                    if x[0]==img1_info or x[1]==img1_info:
                        randChoose = True
                        break
                    
        img0 = Image.open(img0_path)
        img1 = Image.open(img1_path)
        
        if self.transform is not None:#I think the transform is essential if you want to use GPU, because you have to trans data to tensor first.
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        '''
        def to_str(var):
          return str(list(np.reshape(np.asarray(var), (1, np.size(var)))[0]))[1:-1]
        if should_get_same_class : print(img0_path.split("/")[-3] + " " + img1_path.split("/")[-2] + " " + to_str(should_get_same_class))
        '''
        
        return img0, img1 , should_get_same_class #the returned data from dataloader is img=[batch_size,channels,width,length], should_get_same_class=[batch_size,label]
    
    def __len__(self):
        return len(self.relationships)#essential for choose the num of data in one epoch

"""##**Caricamento delle immagini**"""

folder_dataset = dset.ImageFolder(root='train')

trainset = trainingDataset(imageFolderDataset=folder_dataset,
                                        relationships=train,
                                        transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),
                                                                      transforms.ToTensor()
                                                                      ]))     

trainloader = DataLoader(trainset,
                        shuffle=True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.
                        num_workers=2,
                        batch_size=BATCH_SIZE)

valset = trainingDataset(imageFolderDataset=folder_dataset,
                                        relationships=val,
                                        transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),
                                                                      transforms.ToTensor()
                                                                      ]))
valloader = DataLoader(valset,
                        shuffle=True,
                        num_workers=2,
                        batch_size=BATCH_SIZE)

"""##**test per visualizzare il dataloader, utilizza imshow per mostrare le immagini e ci indica se due persone sono parenti o meno con l'utilizzo della classe trainingDataset**"""

#only for visualize data in dataloader, it won't matters if you delete this block.
vis_dataloader = DataLoader(trainset,
                        shuffle=True,
                        num_workers=2,
                        batch_size=8)
dataiter = iter(vis_dataloader)


example_batch = next(dataiter)
concatenated = torch.cat((example_batch[0],example_batch[1]),0)
imshow(torchvision.utils.make_grid(concatenated))
print(example_batch[2].numpy())

"""##**la classe che descrive la rete neurale siamese contenente le caratteristiche e i pesi della rete**"""

class SiameseNetwork(nn.Module):# A simple implementation of siamese network, ResNet50 is used, and then connected by three fc layer.
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        #self.cnn1 = models.resnet50(pretrained=True)#resnet50 doesn't work, might because pretrained model recognize all faces as the same.
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1),
            nn.Conv2d(3, 64, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.Dropout2d(p=.2),
            
            nn.ReflectionPad2d(1),
            nn.Conv2d(64, 64, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.Dropout2d(p=.2),

            nn.ReflectionPad2d(1),
            nn.Conv2d(64, 32, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(32),
            nn.Dropout2d(p=.2),
        )
        self.fc1 = nn.Linear(2*32*100*100, 500)
        self.fc2 = nn.Linear(500, 500)
        self.fc3 = nn.Linear(500, 2)


    def forward(self, input1, input2):#did not know how to let two resnet share the same param.
        output1 = self.cnn1(input1)
        output1 = output1.view(output1.size()[0], -1)#make it suitable for fc layer.
        output2 = self.cnn1(input2)
        output2 = output2.view(output2.size()[0], -1)
        
        output = torch.cat((output1, output2),1)
        output = F.relu(self.fc1(output))
        output = F.relu(self.fc2(output))
        output = self.fc3(output)
        return output

"""##**training con rete neurale**"""

net = SiameseNetwork().cuda()
criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
counter = []
loss_history = [] 
iteration_number= 0

for epoch in range(0,NUMBER_EPOCHS):
    print("Epoch：", epoch, " start.")
    for i, data in enumerate(trainloader,0):
        img0, img1 , labels = data #img=tensor[batch_size,channels,width,length], label=tensor[batch_size,label]
        img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()#move to GPU
        #print("epoch：", epoch, "No." , i, "th inputs", img0.data.size(), "labels", labels.data.size())
        optimizer.zero_grad()#clear the calculated grad in previous batch
        outputs = net(img0,img1)
        loss = criterion(outputs,labels)
        loss.backward()
        optimizer.step()

        if i %10 == 0 :#show changes of loss value after each 10 batches
            #print("Epoch number {}\n Current loss {}\n".format(epoch,loss.item()))
            iteration_number +=10
            counter.append(iteration_number)
            loss_history.append(loss.item())
    #test the network after finish each epoch, to have a brief training result.
    correct_val = 0
    total_val = 0
    with torch.no_grad():#essential for testing!!!!
        for data in valloader:
            img0, img1 , labels = data
            img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()
            outputs = net(img0,img1)
            _, predicted = torch.max(outputs.data, 1)
            total_val += labels.size(0)
            correct_val += (predicted == labels).sum().item()
            
    print('Accuracy of the network on the', total_val, 'val pairs in',val_famillies, ': %d %%' % (100 * correct_val / total_val))
    show_plot(counter,loss_history)

"""##**classe che descrivere le caratteristiche per effettuare il test**"""

class testDataset(Dataset): #different from train dataset, because the data organized in submission.csv is different from train.csv
    
    def __init__(self,transform=None):
        self.test_df = pd.read_csv('/content/drive/Shareddrives/Progetto_FVAB_File/sample_submission.csv')#pandas用来读取csv文件
        self.transform = transform
        
    def __getitem__(self,index):
        #data in submission.csv:
        #       img_pair               is_related
        #face05508.jpg-face01210.jpg       0
        #face05820.jpg-face03938.jpg       0
        
        img0_path = self.test_df.iloc[index].img_pair.split("-")[0]
        img1_path = self.test_df.iloc[index].img_pair.split("-")[1]
        #print(img0_path,'-',img1_path) #reserved to check whether test data is in order.
        
        img0 = Image.open('test/'+img0_path)
        img1 = Image.open('test/'+img1_path)

        if self.transform is not None:
            img0 = self.transform(img0)
            img1 = self.transform(img1)
        
        return img0, img1
    
    def __len__(self):
        return len(self.test_df)

"""##**Caricamento delle immagini del test**"""

testset = testDataset(transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),
                                                                      transforms.ToTensor()
                                                                      ]))
testloader = DataLoader(testset,
                        shuffle=False,
                        num_workers=0,
                        batch_size=1)#Both extra workers and batch size lead to data out of order, the submission.csv will be out of order
#if you have better method, please tell me! thanks a lot!

"""##**Test del dataset e creazione del file csv da inserire su Kaggle**"""

test_df = pd.read_csv('/content/drive/Shareddrives/Progetto_FVAB_File/sample_submission.csv')#pandas用来读取csv文件
predictions=[]
with torch.no_grad():
    for data in testloader:
        img0, img1 = data
        img0, img1 = img0.cuda(), img1.cuda()
        outputs = net(img0,img1)
        _, predicted = torch.max(outputs, 1)
        predictions = np.concatenate((predictions,predicted.cpu().numpy()),0)#taking care of here, the output data format is important for transfer
        

test_df['is_related'] = predictions
test_df.to_csv("/content/drive/Shareddrives/Progetto_FVAB_File/submission.csv", index=False)#submission.csv should be placed directly in current fold.
test_df.head(50)#show the result to be committed

"""##**Salvataggio della rete neurale su Google Drive**"""

salvataggio="/content/drive/Shareddrives/Progetto_FVAB_File/fvab.pth"
torch.save(net,salvataggio)

"""##**Caricamento della rete neurale con relative caratteristiche**"""

salvataggio="/content/drive/Shareddrives/Progetto_FVAB_File/fvab.pth"
#per cambiare la GPU settare << map_location=torch.device('cpu') >> in torch.load
model=torch.load(salvataggio)
model.eval()

"""##**Freeze sui primi 9 layer, Fine tuning sui successivi layer**"""

ct = 0
for param in model.parameters():
  print(ct)
  if ct > 9 and ct<=14: param.requires_grad = True #per settare il fine tuning
  else: param.requires_grad = False #per settare il freeze
  ct = ct + 1

"""##**Estrattore delle caratteristiche**"""

model.fc1 = nn.Linear(2*32*100*100, 500)
model.fc2 = nn.Linear(500, 500)
model.fc3 = nn.Linear(500,400)
model.fc4 = nn.Linear(400,200)
model.fc5 = nn.Linear(200,5)
model.eval()

"""##**Importato i file math e gestito i file in un unico file csv contenente 5 classi, la funzione commentata ci permette di ottenere i nuovi file csv. Uno per il test ed uno per il train**"""

one=0
two=0
three=0
four=0
zero=0
with open('/content/drive/Shareddrives/Progetto_FVAB_File/train_relationships2.csv', 'r') as file:
  if

#F09xx are used for validation.
val_1 = "_11"

#An example of data:"../input/train/F00002/MID1/P0001_face1.jpg"
all_images = glob("/content/KinFaceW-I/images/*/*.jpg")
ppl = [x.split("/") [5] for x in all_images]
#Abbiamo commentato questa parte perchè serve eseguire questa operazione un unica volta
'''
mat1 = scipy.io.loadmat("/content/KinFaceW-I/meta_data/fd_pairs.mat")
mat2 = scipy.io.loadmat("/content/KinFaceW-I/meta_data/fs_pairs.mat")
mat3 = scipy.io.loadmat("/content/KinFaceW-I/meta_data/md_pairs.mat")
mat4 = scipy.io.loadmat("/content/KinFaceW-I/meta_data/ms_pairs.mat")
with open('/content/drive/Shareddrives/Progetto_FVAB_File/train_relationships2.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["p1", "p2","gr_p","tp_r"])
    for x in range (len(mat1['pairs'])):
      gr_p = (mat1['pairs'][x][0]).item(0)
      tp_r = (mat1['pairs'][x][1]).item(0)
      p1 = (mat1['pairs'][x][2]).item(0)
      p2 = (mat1['pairs'][x][3]).item(0)
      if gr_p != 5:
        writer.writerow([p1, p2,1,tp_r])
    for x in range (len(mat2['pairs'])):
      gr_p = (mat2['pairs'][x][0]).item(0)
      tp_r = (mat2['pairs'][x][1]).item(0)
      p1 = (mat2['pairs'][x][2]).item(0)
      p2 = (mat2['pairs'][x][3]).item(0)
      if gr_p != 5:
        writer.writerow([p1, p2,2,tp_r])
    for x in range (len(mat3['pairs'])):
      gr_p = (mat3['pairs'][x][0]).item(0)
      tp_r = (mat3['pairs'][x][1]).item(0)
      p1 = (mat3['pairs'][x][2]).item(0)
      p2 = (mat3['pairs'][x][3]).item(0)
      if gr_p != 5:
        writer.writerow([p1, p2,3,tp_r])
    for x in range (len(mat4['pairs'])):
      gr_p = (mat4['pairs'][x][0]).item(0)
      tp_r = (mat4['pairs'][x][1]).item(0)
      p1 = (mat4['pairs'][x][2]).item(0)
      p2 = (mat4['pairs'][x][3]).item(0)
      if gr_p != 5:
        writer.writerow([p1, p2,4,tp_r])

with open('/content/drive/Shareddrives/Progetto_FVAB_File/sample_submission2.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["img_pair","gr_p","tp_r"])
    for x in range (len(mat1['pairs'])):
      gr_p = (mat1['pairs'][x][0]).item(0)
      tp_r = (mat1['pairs'][x][1]).item(0)
      p1 = (mat1['pairs'][x][2]).item(0)
      p2 = (mat1['pairs'][x][3]).item(0)
      if gr_p == 5:
        writer.writerow(["father-dau/"+p1+",father-dau/"+p2,1,tp_r])
    for x in range (len(mat2['pairs'])):
      gr_p = (mat2['pairs'][x][0]).item(0)
      tp_r = (mat2['pairs'][x][1]).item(0)
      p1 = (mat2['pairs'][x][2]).item(0)
      p2 = (mat2['pairs'][x][3]).item(0)
      if gr_p == 5:
        writer.writerow(["father-son/"+p1+",father-son/"+p2,2,tp_r])
    for x in range (len(mat3['pairs'])):
      gr_p = (mat3['pairs'][x][0]).item(0)
      tp_r = (mat3['pairs'][x][1]).item(0)
      p1 = (mat3['pairs'][x][2]).item(0)
      p2 = (mat3['pairs'][x][3]).item(0)
      if gr_p == 5:
        writer.writerow(["mother-dau/"+p1+",mother-dau/"+p2,3,tp_r])
    for x in range (len(mat4['pairs'])):
      gr_p = (mat4['pairs'][x][0]).item(0)
      tp_r = (mat4['pairs'][x][1]).item(0)
      p1 = (mat4['pairs'][x][2]).item(0)
      p2 = (mat4['pairs'][x][3]).item(0)
      if gr_p == 5:
        writer.writerow(["mother-son/"+p1+",mother-son/"+p2,4,tp_r])
'''

relationships = pd.read_csv("/content/drive/Shareddrives/Progetto_FVAB_File/train_relationships2.csv")
relationships = list(zip(relationships.p1.values, relationships.p2.values,relationships.tp_r.values,relationships.gr_p.values))#For a List like[p1 p2], zip can return a result like [(p1[0],p2[0]),(p1[1],p2[1]),...]
relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]#filter unused relationships

train = [x for x in relationships if  val_1  not in x[0]]
val = [x for x in relationships if val_1 in x[0]]

print("Total train pairs:", len(train))    
print("Total val pairs:", len(val))

"""##**definiamo la classe che utilizziamo durante la fase di training sul secondo dataset per ricevere le coppia su cui la rete deve allenarsi, con cinque classi da 0 a 4**"""

class trainingDataset(Dataset):#Get two images and whether they are related.
    
    def __init__(self,imageFolderDataset, relationships, transform=None):
        self.imageFolderDataset = imageFolderDataset    
        self.relationships = relationships #choose either train or val dataset to use
        self.transform = transform
        
    def __getitem__(self,index):
        img0_info = self.relationships[index][0]#for each relationship in train_relationships.csv, the first img comes from first row, and the second is either specially choosed related person or randomly choosed non-related person
        img0_path = glob("/content/KinFaceW-I/images/*/"+img0_info)
        img0_path = random.choice(img0_path)
        
        cand_relationships = [x for x in self.relationships if x[0]==img0_info or x[1]==img0_info]#found all candidates related to person in img0
        
        should_get_same_class = 1
        for i in range(0,len(cand_relationships)):
          if cand_relationships[i][2] == 0:#in case no relationship is mensioned. But it is useless here because I choose the first person line by line.
            should_get_same_class = random.randint(0,1) 
      
        
        if should_get_same_class == 1:#1 means related, and 0 means non-related.       
          randChoose = True
          while randChoose:
            img1_info = random.choice(cand_relationships)#choose the second person from related relationships 
            if img1_info[2]== 1: 
              randChoose = False
          if img1_info[0]!=img0_info:
              img1_info=img1_info[0]
          else:
              img1_info=img1_info[1]
          img1_path = glob("/content/KinFaceW-I/images/*/"+img1_info)#randomly choose a img of this person
          img1_path = random.choice(img1_path)
          should_get_same_class = cand_relationships[0][3].item()
        
        else:#0 means non-related.       
          randChoose = True
          while randChoose:
            img1_info = random.choice(cand_relationships)#choose the second person from related relationships 
            if img1_info[2] == 0: 
              randChoose = False
          if img1_info[0]!= img0_info:
              img1_info = img1_info[0]
          else:
              img1_info=img1_info[1]
          img1_path = glob("/content/KinFaceW-I/images/*/"+img1_info)#randomly choose a img of this person
          img1_path = random.choice(img1_path)  
        
        img0 = Image.open(img0_path)
        img1 = Image.open(img1_path)
        
        if self.transform is not None:#I think the transform is essential if you want to use GPU, because you have to trans data to tensor first.
            img0 = self.transform(img0)
            img1 = self.transform(img1)
        
        '''
        def to_str(var):
          return str(list(np.reshape(np.asarray(var), (1, np.size(var)))[0]))[1:-1]
        if should_get_same_class : print(img0_path.split("/")[5] + " " + img1_path.split("/")[5] + " " + to_str(should_get_same_class))
        '''

        return img0, img1 , should_get_same_class #the returned data from dataloader is img=[batch_size,channels,width,length], should_get_same_class=[batch_size,label]
     
    def __len__(self):
        return len(self.relationships)#essential for choose the num of data in one epoch

"""## **Caricamento delle immagini**"""

folder_dataset = dset.ImageFolder(root='/content/KinFaceW-I/images')


trainset = trainingDataset(imageFolderDataset=folder_dataset,
                                        relationships=train,
                                        transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),
                                                                      #transforms.RandomRotation(20),
                                                                      transforms.ToTensor()
                                                                      ]))

trainloader = DataLoader(trainset,
                        shuffle = True,#whether randomly shuffle data in each epoch, but cannot let data in one batch in order.
                        num_workers = 2,
                        batch_size = BATCH_SIZE)


valset = trainingDataset(imageFolderDataset=folder_dataset,
                                        relationships=val,
                                        transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),
                                                                      #transforms.RandomRotation(20),
                                                                      transforms.ToTensor()
                                                                      ]))


valloader = DataLoader(valset, shuffle = True,
                       num_workers = 2,
                       batch_size = BATCH_SIZE)

"""##**test per visualizzare il dataloader, utilizza imshow per mostrare le immagini e ci indica se due persone sono parenti o meno con l'utilizzo della classe trainingDataset sul secondo dataset**"""

#only for visualize data in dataloader, it won't matters if you delete this block.
vis_dataloader = DataLoader(trainset,
                        shuffle=True,
                        num_workers=2,
                        batch_size=8)
dataiter = iter(vis_dataloader)


example_batch = next(dataiter)
concatenated = torch.cat((example_batch[0],example_batch[1]),0)
imshow(torchvision.utils.make_grid(concatenated))
print(example_batch[2].numpy())

"""##**Training sul secondo dataset della rete neurale pre allenata sul primo dataset**"""

net = model.cuda()
criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss
optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)

counter = []
loss_history = [] 
iteration_number = 0

for epoch in range(0,40):
    print("Epoch：", epoch, " start.")
    for i, data in enumerate(trainloader,0):
        img0, img1 , labels = data #img=tensor[batch_size,channels,width,length], label=tensor[batch_size,label]
        img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()#move to GPU
        #print("epoch：", epoch, "No." , i, "th inputs", img0.data.size(), "labels", labels.data.size())
        optimizer.zero_grad()#clear the calculated grad in previous batch
        outputs = net(img0,img1)
        loss = criterion(outputs,labels)
        loss.backward()
        optimizer.step()
        if i % 10 == 0 :#show changes of loss value after each 10 batches
          #print("Epoch number {}\n Current loss {}\n".format(epoch,loss.item()))
          iteration_number += 10
          counter.append(iteration_number)
          loss_history.append(loss.item())
    
    #test the network after finish each epoch, to have a brief training result.
    correct_val = 0
    total_val = 0
    with torch.no_grad():#essential for testing!!!!
        for data in valloader:
            img0, img1 , labels = data
            img0, img1 , labels = img0.cuda(), img1.cuda() , labels.cuda()
            outputs = net(img0,img1)
            _, predicted = torch.max(outputs.data, 1)
            total_val += labels.size(0)
            correct_val += (predicted == labels).sum().item()
            
    print('Accuracy of the network on the', total_val, ': %d %%' % (100 * correct_val / total_val))
    show_plot(counter,loss_history)

"""##**salvataggio della seconda rete neurale**"""

salvataggio="/content/drive/Shareddrives/Progetto_FVAB_File/fvab2.pth"
torch.save(net,salvataggio)

"""##**Caricamento della seconda rete neurale**"""

salvataggio="/content/drive/Shareddrives/Progetto_FVAB_File/fvab2.pth"
net=torch.load(salvataggio)

"""##**classe che descrivere le caratteristiche per effettuare il test**"""

class testDataset(Dataset): #different from train dataset, because the data organized in submission.csv is different from train.csv
    
    def __init__(self, transform=None):
        self.test_df = pd.read_csv('/content/drive/Shareddrives/Progetto_FVAB_File/sample_submission2.csv')#pandas用来读取csv文件
        self.transform = transform
        
    def __getitem__(self,index):
        
        img0_path = self.test_df.iloc[index].img_pair.split(",")[0]
        img1_path = self.test_df.iloc[index].img_pair.split(",")[1]
        #print(img0_path,'-',img1_path) #reserved to check whether test data is in order.
        
        img0 = Image.open('/content/KinFaceW-I/images/'+img0_path)
        img1 = Image.open('/content/KinFaceW-I/images/'+img1_path)

        if self.transform is not None:
            img0 = self.transform(img0)
            img1 = self.transform(img1)
        
        return img0, img1
    
    def __len__(self):
        return len(self.test_df)

"""##**Caricamento delle immagini**"""

testset = testDataset(transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),
                                                                      transforms.ToTensor()
                                                                      ]))
testloader = DataLoader(testset,
                        shuffle=False,
                        num_workers=0,
                        batch_size=1)#Both extra workers and batch size lead to data out of order, the submission.csv will be out of order
#if you have better method, please tell me! thanks a lot!

"""##**Test del secondo dataset e creazione del file csv**"""

test_df = pd.read_csv('/content/drive/Shareddrives/Progetto_FVAB_File/sample_submission2.csv')#pandas用来读取csv文件
predictions=[]
with torch.no_grad():
    for data in testloader:
        img0, img1 = data
        img0, img1 = img0.cuda(), img1.cuda()
        outputs = net(img0,img1)
        _, predicted = torch.max(outputs, 1)
        predictions = np.concatenate((predictions,predicted.cpu().numpy()),0)#taking care of here, the output data format is important for transfer
        
test_df['is_related'] = predictions
test_df.to_csv("/content/drive/Shareddrives/Progetto_FVAB_File/submission2.csv", index=False)#submission.csv should be placed directly in current fold.
test_df.head(50)#show the result to be committed

"""##**raccolta dati dal csv del test**"""

relationships2 = pd.read_csv("/content/drive/Shareddrives/Progetto_FVAB_File/submission2.csv")
actual = []
predict = []

for i in range(0,len(relationships2)):
  if (relationships2['tp_r'][i] == 0):
    actual.append(relationships2['tp_r'][i])
  else:
    actual.append(relationships2['gr_p'][i])
  predict.append(relationships2['is_related'][i])

"""##**matrice di confusione**"""

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

cm = confusion_matrix(actual, predict)
labels = ['nkf','fd', 'fs','md','ms']
plt.figure(figsize=(5,5))
plot_confusion_matrix(cm, labels)


true_p = [0,0,0,0,0]
true_n = [0,0,0,0,0]
false_p = [0,0,0,0,0]
false_n = [0,0,0,0,0]
totale_corrette = 0
for i in range (0,5):
  totale_corrette = totale_corrette + cm[i][i]
  true_p[i] = cm[i][i]
  for j in range (0,5):
    if j != i : 
      false_p[i] = false_p[i] + cm[i][j]
      false_n[i] = false_n[i] + cm[j][i]
      true_n[i] = true_n[i] + cm[j][j]
 
recall = [0,0,0,0,0]
precision = [0,0,0,0,0] 
accuracy = [0,0,0,0,0] 
f1_score = [0,0,0,0,0] 
for i in range (0,5):
  recall[i] = true_p[i]/(true_p[i]+false_n[i])
  precision[i]=true_p[i]/(true_p[i]+true_n[i])
  f1_score[i]=format(2*((precision[i]*recall[i])/(precision[i]+recall[i])),'.2f')
  accuracy[i]=format((true_p[i]+false_n[i])/(true_p[i]+false_p[i]+false_n[i]+true_n[i]),'.2f')
  recall[i] = format(recall[i],'.2f')
  precision[i]= format(precision[i],'.2f')
print("Accuracy tot: " + format(totale_corrette/len(actual),'.2f'))


import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(header=dict(values=['','Recall', 'Precision','Accuracy','F1_score']),
                 cells=dict(values=[labels,recall,precision,accuracy,f1_score]))])
fig.show()